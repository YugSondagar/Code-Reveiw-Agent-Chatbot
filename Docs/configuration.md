# âš™ï¸ Configuration

This document explains how to **configure and customize** the AI Code Review Agent.

All configurations are designed to be **simple, centralized, and extensible**, allowing developers to tune performance, models, and analysis behavior.

---

## ğŸ“ Configuration File Location

All configurable settings are stored in:

```text
backend/config.py
```

This approach keeps configuration **separate from business logic**, following industry best practices.

---

## ğŸ§  LLM Configuration

### Default Model

```python
OLLAMA_MODEL = "deepseek-coder:6.7b"
```

You can switch models based on your hardware or preferences.

### Supported Models (Examples)

| Model               | Use Case                 |
| ------------------- | ------------------------ |
| deepseek-coder:6.7b | Best overall code review |
| qwen2.5-coder:7b    | Better structured output |
| codellama:7b        | Lightweight alternative  |

After changing the model, ensure it is pulled:

```bash
ollama pull <model-name>
```

---

## â±ï¸ Request & Timeout Settings

```python
OLLAMA_TIMEOUT = 120  # seconds
```

* Increase for large codebases
* Reduce for faster responses

---

## ğŸ§© Chunking Configuration

Large files are split to stay within LLM context limits.

```python
MAX_CHUNK_SIZE = 2000  # tokens / characters
```

### Guidelines

* Smaller chunks â†’ safer but slower
* Larger chunks â†’ faster but risk context overflow

---

## ğŸ§ª Static Analysis Configuration

### Enable / Disable Tools

```python
ENABLE_PYLINT = True
ENABLE_BANDIT = True
ENABLE_RADON = True
```

You can disable any tool if not required.

---

## ğŸŒ Language Support Configuration

Supported languages are defined using mappings:

```python
SUPPORTED_LANGUAGES = {
    "py": "python",
    "js": "javascript",
    "java": "java"
}
```

Add new languages by extending this mapping.

---

## ğŸ“ Prompt Configuration

Prompt templates are stored in:

```text
backend/prompts/review_prompt.txt
```

### Why External Prompts?

* Easier prompt tuning
* Version control
* Better experiment tracking

Recommended changes:

* Tone (strict vs friendly)
* Output format (JSON, markdown)
* Depth of analysis

---

## ğŸ” Security & Privacy Settings

```python
STORE_CODE = False
DEBUG_MODE = False
```

* Code is **not stored by default**
* Enable debug mode only in development

---

## ğŸš€ Performance Tuning Tips

* Use SSD storage
* Ensure Ollama has enough RAM
* Prefer fewer, larger chunks on high-memory systems
* Disable unused static analyzers

---

## ğŸ›£ï¸ Future Configuration Options

Planned enhancements:

* Environment-based configs (.env)
* Per-language analysis rules
* User-defined prompts
* Async worker configuration

---

## â­ Summary

The configuration system allows developers to **easily adapt the project** for different environmentsâ€”from hackathon demos to internal enterprise tools.

Next:

* See **user-guide.md** to learn how to use the application effectively.

---

Happy configuring! âš™ï¸ğŸš€
